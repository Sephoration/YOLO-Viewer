"""
é€»è¾‘åè°ƒæ§åˆ¶å™¨
è´Ÿè´£è¿æ¥UIã€æ’­æ”¾å™¨ã€æŠ“å–å™¨å’ŒYOLOæ¨ç†å¼•æ“
ä½¿ç”¨QThreadç®¡ç†è§†é¢‘æ’­æ”¾çº¿ç¨‹
"""

import os
import sys
import time
import traceback
import threading
from pathlib import Path
from typing import Dict, Any, Optional

from PySide6.QtCore import QObject, Signal, Qt, QThread, QMutex, QWaitCondition, QTimer
from PySide6.QtGui import QPixmap, QImage
from PySide6.QtWidgets import QMessageBox, QFileDialog

from window_ui import YOLOMainWindowUI
from baseDetect import baseDetect

# å¯¼å…¥é…ç½®æ–‡ä»¶
from config import AppConfig

# æ·»åŠ QMutexLockerè¾…åŠ©ç±»
class QMutexLocker:
    """ç”¨äºç®€åŒ–QMutexçš„ä½¿ç”¨ï¼Œç±»ä¼¼äºC++çš„QMutexLocker"""
    def __init__(self, mutex):
        self.mutex = mutex
        self.mutex.lock()
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.mutex.unlock()


class VideoPlayerThread(QThread):
    """
    ä½¿ç”¨Qtçº¿ç¨‹æœºåˆ¶ã€æä¾›æ›´å¯é çš„çº¿ç¨‹ç®¡ç†
    """
    
    frame_ready = Signal(QImage)  # å¸§å°±ç»ªä¿¡å·ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    status_update = Signal(str)   # çŠ¶æ€æ›´æ–°
    progress_updated = Signal(int, int, float)  # è¿›åº¦æ›´æ–°ä¿¡å· (å½“å‰å¸§, æ€»å¸§æ•°, å½“å‰æ—¶é—´)
    finished = Signal()           # æ’­æ”¾å®Œæˆ
    
    def __init__(self):
        super().__init__()
        self.playing = False
        self.paused = False
        self.cap = None
        self.current_frame = None  # å½“å‰å¸§ï¼ˆnumpy arrayï¼‰
        self.frame_mutex = QMutex()  # ç”¨äºå¸§æ•°æ®è®¿é—®çš„äº’æ–¥é”
        self.cap_mutex = QMutex()    # ä¸“é—¨ç”¨äºä¿æŠ¤capå¯¹è±¡æ“ä½œçš„äº’æ–¥é”
        self.wait_condition = QWaitCondition()  # ç”¨äºæš‚åœæ§åˆ¶
        
        # è§†é¢‘ä¿¡æ¯
        self.total_frames = 0
        self.current_frame_num = 0
        self.fps = AppConfig.VIDEO_SETTINGS['min_fps']  # ä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤FPS
        self.duration = 0.0
        
        # æ’­æ”¾æº
        self.video_path = None
        self.camera_id = AppConfig.CAMERA_SETTINGS['default_camera_id']  # ä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤æ‘„åƒå¤´ID
        self.play_mode = None  # 'video' or 'camera'
        
        # ä¼˜åŒ–å¼€å…³
        self._use_grab = AppConfig.PLAYER_SETTINGS['use_grab_method']  # ä½¿ç”¨é…ç½®ä¸­çš„ä¼˜åŒ–è®¾ç½®
        
        # ç¦ç”¨OpenCVçš„å¤šçº¿ç¨‹åŠŸèƒ½ä»¥é¿å…FFmpegçº¿ç¨‹å†²çª
        self._disable_cv2_multithreading()
        
    def _disable_cv2_multithreading(self):
        """ç¦ç”¨OpenCVçš„å¤šçº¿ç¨‹åŠŸèƒ½ä»¥é¿å…ä¸FFmpegçš„çº¿ç¨‹å†²çª"""
        try:
            import cv2
            cv2.setNumThreads(0)
            cv2.ocl.setUseOpenCL(False)
        except Exception:
            pass
    
    def play_video(self, video_path: str):
        """æ’­æ”¾è§†é¢‘æ–‡ä»¶"""
        self.stop()
        
        with QMutexLocker(self.frame_mutex):
            self.video_path = video_path
            self.camera_id = None
            self.play_mode = 'video'
            self.playing = True
            self.paused = False
        
        # å¦‚æœçº¿ç¨‹æœªå¯åŠ¨æˆ–å·²ç»“æŸï¼Œé‡æ–°å¯åŠ¨
        if not self.isRunning():
            self.start(QThread.NormalPriority)
    
    def play_camera(self, camera_id: int = 0):
        """æ’­æ”¾æ‘„åƒå¤´"""
        self.stop()
        
        with QMutexLocker(self.frame_mutex):
            self.video_path = None
            self.camera_id = camera_id
            self.play_mode = 'camera'
            self.playing = True
            self.paused = False
        
        # å¦‚æœçº¿ç¨‹æœªå¯åŠ¨æˆ–å·²ç»“æŸï¼Œé‡æ–°å¯åŠ¨
        if not self.isRunning():
            self.start(QThread.NormalPriority)
    
    def stop(self):
        """åœæ­¢æ’­æ”¾"""
        # å®‰å…¨åœ°è®¾ç½®åœæ­¢æ ‡å¿—
        with QMutexLocker(self.frame_mutex):
            self.playing = False
            self.paused = False
            self.wait_condition.wakeAll()  # å”¤é†’å¯èƒ½åœ¨ç­‰å¾…çš„çº¿ç¨‹
        
        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        if self.isRunning():
            self.wait(3000)  # å¢åŠ ç­‰å¾…æ—¶é—´åˆ°3ç§’
        
        # å®‰å…¨åœ°é‡Šæ”¾èµ„æº
        with QMutexLocker(self.cap_mutex):
            if self.cap:
                try:
                    self.cap.release()
                except Exception:
                    traceback.print_exc()
                finally:
                    self.cap = None
        
        self.finished.emit()
    
    def pause(self):
        """æš‚åœæ’­æ”¾"""
        with QMutexLocker(self.frame_mutex):
            if not self.playing:
                return
            self.paused = True
    
    def resume(self):
        """ç»§ç»­æ’­æ”¾"""
        with QMutexLocker(self.frame_mutex):
            if not self.playing:
                return
            self.paused = False
            self.wait_condition.wakeAll()  # å”¤é†’ç­‰å¾…çš„çº¿ç¨‹
    
    def get_current_frame(self):
        """è·å–å½“å‰å¸§ï¼ˆç”¨äºæŠ“å–ï¼‰"""
        with QMutexLocker(self.frame_mutex):
            if self.current_frame is not None and hasattr(self.current_frame, 'copy'):
                return self.current_frame.copy()
            return None
    
    def seek_frame(self, target_frame: int):
        """è·³è½¬åˆ°æŒ‡å®šå¸§"""
        try:
            import cv2
            
            # é¦–å…ˆæ£€æŸ¥capå¯¹è±¡æ˜¯å¦æœ‰æ•ˆ
            with QMutexLocker(self.cap_mutex):
                if not self.cap or not self.cap.isOpened() or self.play_mode != 'video':
                    return
                
                # è·³è½¬åˆ°ç›®æ ‡å¸§
                try:
                    self.cap.set(cv2.CAP_PROP_POS_FRAMES, max(0, int(target_frame)))
                except Exception as e:
                    self.status_update.emit(f"è·³è½¬å¤±è´¥: {str(e)}")
                    return
                
                # è¯»å–å¸§
                if self._use_grab:
                    try:
                        self.cap.grab()
                        ret, frame = self.cap.retrieve()
                    except Exception:
                        ret = False
                else:
                    try:
                        ret, frame = self.cap.read()
                    except Exception:
                        ret = False
                
                if not ret or frame is None:
                    return
                
                # æ›´æ–°å¸§è®¡æ•°
                try:
                    pos = int(self.cap.get(cv2.CAP_PROP_POS_FRAMES))
                    if pos >= 0:
                        self.current_frame_num = pos
                    else:
                        self.current_frame_num = max(0, int(target_frame))
                except:
                    self.current_frame_num = max(0, int(target_frame))
                
                # æ›´æ–°å½“å‰å¸§æ•°æ®
                with QMutexLocker(self.frame_mutex):
                    self.current_frame = frame.copy()
            
            current_time = self.current_frame_num / max(1.0, self.fps)
            self.progress_updated.emit(self.current_frame_num, self.total_frames, current_time)
            
            if not self.current_frame.flags['C_CONTIGUOUS']:
                frame_copy = self.current_frame.copy()
            else:
                frame_copy = self.current_frame
            height, width, channel = frame_copy.shape
            bytes_per_line = 3 * width
            q_img = QImage(frame_copy.data, width, height, bytes_per_line, QImage.Format_BGR888).copy()
            self.frame_ready.emit(q_img)
        except Exception:
            traceback.print_exc()
    
    def run(self):
        """çº¿ç¨‹è¿è¡Œå‡½æ•°"""
        try:
            if self.play_mode == 'video' and self.video_path:
                self._video_playback()
            elif self.play_mode == 'camera' and self.camera_id is not None:
                self._camera_playback()
        except Exception as e:
            self.status_update.emit(f"æ’­æ”¾é”™è¯¯: {str(e)}")
            traceback.print_exc()
        finally:
            self.playing = False
            self.paused = False
            if self.cap:
                try:
                    self.cap.release()
                except:
                    pass
                self.cap = None
            self.finished.emit()
    
    def _video_playback(self):
        """è§†é¢‘æ’­æ”¾å®ç°"""
        import time
        time.sleep(0.05)

        try:
            import cv2
            import numpy as np

            # åˆå§‹åŒ–è§†é¢‘æ•è·å¯¹è±¡
            with QMutexLocker(self.cap_mutex):
                self.cap = cv2.VideoCapture(self.video_path)
                if not self.cap.isOpened():
                    self.status_update.emit(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {self.video_path}")
                    return

                # å°è¯•è®¾ç½®è¾ƒå°çš„å†…éƒ¨ç¼“å†²
                try:
                    self.cap.set(cv2.CAP_PROP_BUFFERSIZE, AppConfig.VIDEO_SETTINGS['default_buffer_size'])  # ä½¿ç”¨é…ç½®ä¸­çš„ç¼“å†²å¤§å°
                except Exception:
                    pass

                # è·å–è§†é¢‘ä¿¡æ¯
                try:
                    self.total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
                except:
                    self.total_frames = 1000  # é»˜è®¤å¸§æ•°
                
                try:
                    self.fps = self.cap.get(cv2.CAP_PROP_FPS)
                except:
                    self.fps = AppConfig.VIDEO_SETTINGS['min_fps']
                
                if self.fps <= 0:
                    self.fps = AppConfig.VIDEO_SETTINGS['min_fps']

                if self.total_frames > 0:
                    self.duration = self.total_frames / self.fps
                else:
                    self.total_frames = 1000

                try:
                    self.current_frame_num = int(self.cap.get(cv2.CAP_PROP_POS_FRAMES))
                except:
                    self.current_frame_num = 0

                # é¢„å…ˆè¯»å–å‡ å¸§ä»¥ç¡®ä¿åˆå§‹åŒ–æ­£å¸¸
                if self._use_grab:
                    # ä»é…ç½®ä¸­è·å–é¢„åŠ è½½å¸§æ•°æˆ–ä½¿ç”¨é»˜è®¤å€¼
                    preload_frames = getattr(AppConfig.VIDEO_SETTINGS, 'frame_preload_count', 2)
                    for _ in range(preload_frames):
                        try:
                            self.cap.grab()
                        except Exception:
                            break

            self.status_update.emit(f"å¼€å§‹æ’­æ”¾è§†é¢‘: {os.path.basename(self.video_path)}")
            self.status_update.emit(f"æ€»å¸§æ•°: {self.total_frames}, FPS: {self.fps:.2f}")

            frame_interval = 1.0 / self.fps if self.fps > 0 else 0.033

            while self.playing:
                # æ£€æŸ¥æš‚åœçŠ¶æ€
                with QMutexLocker(self.frame_mutex):
                    if self.paused:
                        self.wait_condition.wait(self.frame_mutex)
                        if not self.playing:
                            break
                        continue

                loop_start = time.time()

                # è¯»å–å¸§ï¼Œæ‰€æœ‰capæ“ä½œéƒ½åœ¨é”ä¿æŠ¤ä¸‹è¿›è¡Œ
                frame = None
                frame_read_ok = False
                
                with QMutexLocker(self.cap_mutex):
                    if not self.cap or not self.cap.isOpened():
                        break
                    
                    try:
                        if self._use_grab:
                            ok = self.cap.grab()
                            if ok:
                                ret, frame = self.cap.retrieve()
                                frame_read_ok = ret and frame is not None
                        else:
                            ret, frame = self.cap.read()
                            frame_read_ok = ret and frame is not None
                            
                        # å¸§è¯»å–å¤±è´¥æ—¶çš„å¤„ç†
                        if not frame_read_ok:
                            try:
                                self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                                with QMutexLocker(self.frame_mutex):
                                    self.current_frame_num = 0
                                continue
                            except Exception:
                                break
                        
                        # æ›´æ–°å¸§è®¡æ•°
                        try:
                            pos = int(self.cap.get(cv2.CAP_PROP_POS_FRAMES))
                            with QMutexLocker(self.frame_mutex):
                                if pos >= 0:
                                    self.current_frame_num = pos
                                else:
                                    self.current_frame_num += 1
                        except Exception:
                            with QMutexLocker(self.frame_mutex):
                                self.current_frame_num += 1
                    except Exception as e:
                        self.status_update.emit(f"è¯»å–å¸§é”™è¯¯: {str(e)}")
                        break

                # æ›´æ–°å½“å‰å¸§æ•°æ®
                if frame_read_ok and frame is not None:
                    with QMutexLocker(self.frame_mutex):
                        self.current_frame = frame.copy()

                    # å‘é€è¿›åº¦æ›´æ–°
                    with QMutexLocker(self.frame_mutex):
                        current_time = self.current_frame_num / self.fps if self.fps > 0 else 0.0
                    self.progress_updated.emit(self.current_frame_num, self.total_frames, current_time)

                    # è½¬æ¢å¹¶å‘é€å¸§
                    try:
                        if not frame.flags['C_CONTIGUOUS']:
                            frame = np.ascontiguousarray(frame)
                        height, width, channel = frame.shape
                        bytes_per_line = 3 * width

                        q_img = QImage(frame.data, width, height, bytes_per_line, QImage.Format_BGR888).copy()
                        self.frame_ready.emit(q_img)
                    except Exception:
                        traceback.print_exc()

                # æ§åˆ¶å¸§ç‡
                elapsed = time.time() - loop_start
                wait_time = max(0.0, frame_interval - elapsed) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
                
                # çŸ­æš‚ç¡çœ ï¼Œä½¿ç”¨æ›´ç®€å•çš„æ–¹å¼é¿å…å¤æ‚çš„è®¡æ—¶å™¨æ“ä½œ
                if wait_time > 0:
                    QThread.msleep(int(wait_time))
                
                # å†æ¬¡æ£€æŸ¥æš‚åœçŠ¶æ€
                with QMutexLocker(self.frame_mutex):
                    if self.paused:
                        self.wait_condition.wait(self.frame_mutex)
                        if not self.playing:
                            break

        except Exception:
            self.status_update.emit(f"è§†é¢‘æ’­æ”¾é”™è¯¯")
            traceback.print_exc()
    
    def _camera_playback(self): 
        """æ‘„åƒå¤´æ’­æ”¾å®ç°"""
        try:
            import cv2
            import numpy as np
            import time
            import traceback
            from PySide6.QtCore import QThread, QMutexLocker
            
            # åˆå§‹åŒ–æ‘„åƒå¤´æ•è·å¯¹è±¡
            with QMutexLocker(self.cap_mutex):
                self.cap = cv2.VideoCapture(self.camera_id)
                if not self.cap.isOpened():
                    self.status_update.emit(f"æ— æ³•æ‰“å¼€æ‘„åƒå¤´: {self.camera_id}")
                    return
                
                # âœ… ä¼˜åŒ–æ‘„åƒå¤´å‚æ•°è®¾ç½®
                # ä½¿ç”¨é…ç½®ä¸­çš„åˆ†è¾¨ç‡ä»¥æé«˜å¸§ç‡
                width, height = AppConfig.CAMERA_SETTINGS['resolution']
                self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)   
                self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
                
                # è®¾ç½®MJPGç¼–ç ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                try:
                    self.cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc('M','J','P','G'))
                except:
                    pass
                
                # å‡å°‘ç¼“å†²åŒº
                try:
                    self.cap.set(cv2.CAP_PROP_BUFFERSIZE, AppConfig.CAMERA_SETTINGS['buffer_size'])
                except:
                    pass
                
                # è®¾ç½®å¸§ç‡ï¼ˆå¦‚æœæ‘„åƒå¤´æ”¯æŒï¼‰
                try:
                    self.cap.set(cv2.CAP_PROP_FPS, AppConfig.CAMERA_SETTINGS['target_fps'])
                except:
                    pass
            
            # é¢„çƒ­æ‘„åƒå¤´
            for _ in range(AppConfig.CAMERA_SETTINGS['warmup_frames']):
                try:
                    ret_warm, _ = self.cap.read()
                    if not ret_warm:
                        break
                except:
                    break
            
            # ä½¿ç”¨é…ç½®ä¸­çš„åˆ†è¾¨ç‡æ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯
            width, height = AppConfig.CAMERA_SETTINGS['resolution']
            self.status_update.emit(f"å¼€å§‹æ‘„åƒå¤´å®æ—¶æ˜¾ç¤º ({width}x{height})")
            
            frame_count = 0
            start_time = time.time()
            
            while self.playing:
                # æ£€æŸ¥æš‚åœçŠ¶æ€
                with QMutexLocker(self.frame_mutex):
                    if self.paused:
                        self.wait_condition.wait(self.frame_mutex)
                        if not self.playing:
                            break
                        continue
                
                # âœ… æ›´ç®€å•çš„å¸§è¯»å–é€»è¾‘
                frame = None
                frame_read_ok = False
                
                with QMutexLocker(self.cap_mutex):
                    if not self.cap or not self.cap.isOpened():
                        break
                    
                    try:
                        ret, frame = self.cap.read()
                        frame_read_ok = ret and frame is not None
                    except Exception:
                        frame_read_ok = False
                
                if not frame_read_ok or frame is None:
                    self.status_update.emit("æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢ï¼Œé‡è¯•...")
                    QThread.msleep(10)
                    continue
                
                # âœ… é™åˆ¶FPSï¼Œé¿å…è¿‡å¿«å¤„ç†
                frame_count += 1
                elapsed = time.time() - start_time
                if elapsed >= 1.0:
                    fps = frame_count / elapsed
                    self.status_update.emit(f"æ‘„åƒå¤´FPS: {fps:.1f}")
                    frame_count = 0
                    start_time = time.time()
                
                # æ›´æ–°å½“å‰å¸§
                with QMutexLocker(self.frame_mutex):
                    self.current_frame = frame.copy()
                
                # è½¬æ¢å¹¶å‘é€å¸§
                try:
                    # âœ… ç¡®ä¿å†…å­˜è¿ç»­
                    if not frame.flags['C_CONTIGUOUS']:
                        frame = np.ascontiguousarray(frame)
                    
                    height, width, channel = frame.shape
                    bytes_per_line = 3 * width
                    
                    # âœ… åˆ›å»ºQImageï¼Œç«‹å³å¤åˆ¶æ•°æ®
                    q_img = QImage(
                        frame.data, width, height, bytes_per_line,
                        QImage.Format_BGR888
                    ).copy()  # é‡è¦ï¼šå¤åˆ¶æ•°æ®ä»¥é¿å…å¼•ç”¨é—®é¢˜
                    
                    self.frame_ready.emit(q_img)
                except Exception:
                    traceback.print_exc()
                
                # âœ… ç®€å•çš„å»¶æ—¶æ§åˆ¶ï¼Œç›®æ ‡15-20FPS
                QThread.msleep(50)  # 50ms = 20FPS
                
        except Exception:
            self.status_update.emit(f"æ‘„åƒå¤´æ’­æ”¾é”™è¯¯")
            traceback.print_exc()
        finally:
            with QMutexLocker(self.cap_mutex):
                if self.cap:
                    try:
                        self.cap.release()
                    except:
                        pass
                    self.cap = None


class YOLOMainController(QObject):
    """ä¸»é€»è¾‘åè°ƒæ§åˆ¶å™¨"""
    
    def __init__(self, ui_window: YOLOMainWindowUI):
        super().__init__()
        self.ui = ui_window
        
        # æ ¸å¿ƒç»„ä»¶
        self.video_player = VideoPlayerThread()  # ä½¿ç”¨åŸºäºQThreadçš„æ’­æ”¾å™¨
        # å»¶è¿Ÿå¯¼å…¥FrameGrabberThreadä»¥é¿å…å¾ªç¯å¯¼å…¥é—®é¢˜
        try:
            from frame_grabber import FrameGrabberThread
            self.frame_grabber = FrameGrabberThread(self.video_player)  # ä½¿ç”¨æ–°çš„QThreadç‰ˆæœ¬æŠ“å–å™¨
            print("FrameGrabberThreadå¯¼å…¥æˆåŠŸ")
        except ImportError as e:
            print(f"å¯¼å…¥FrameGrabberThreadå¤±è´¥: {e}")
            self.frame_grabber = None
        self.yolo_processor = None                   # YOLOæ¨ç†å¼•æ“
        
        # çŠ¶æ€å˜é‡
        self.model_loaded = False
        self.model_path = None
        self.model_mode = None  # 'detect', 'classify', 'pose'
        
        # å¤„ç†çŠ¶æ€
        self.is_processing = False      # æ˜¯å¦æ­£åœ¨YOLOå¤„ç†
        self.is_playing = False         # æ˜¯å¦æ­£åœ¨æ’­æ”¾
        self.current_file = None
        self.current_mode = None        # 'image', 'video', 'camera'
        
        # é»˜è®¤å‚æ•° - ä»é…ç½®æ–‡ä»¶è¯»å–
        self.default_params = {
            'iou_threshold': AppConfig.YOLO_SETTINGS['default_iou'],
            'confidence_threshold': AppConfig.YOLO_SETTINGS['default_confidence'],
            'delay_ms': 10,  # è¿™ä¸ªå€¼å¯ä»¥è€ƒè™‘æ·»åŠ åˆ°é…ç½®ä¸­
            'line_width': AppConfig.YOLO_SETTINGS['default_line_width']
        }
        
        # è·å–UIç»„ä»¶å¼•ç”¨
        self.left_panel = self.ui.get_left_panel()
        self.right_panel = self.ui.get_right_panel()
        
        # åˆå§‹åŒ–UIçŠ¶æ€
        self._init_ui_state()
        # è¿æ¥ä¿¡å·
        self._connect_signals()
        
        print("YOLOé€»è¾‘æ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ")
    

    
    def _init_ui_state(self):
        """åˆå§‹åŒ–UIçŠ¶æ€"""
        # è®¾ç½®é»˜è®¤å‚æ•°
        self.right_panel.set_parameters(**self.default_params)
        
        # æ˜¾ç¤ºåˆå§‹çŠ¶æ€
        self.left_panel.clear_display()
        self.right_panel.update_model_info()
        
        # è®¾ç½®æ§åˆ¶æŒ‰é’®çŠ¶æ€
        self.right_panel.set_control_state(False)
    
    def _connect_signals(self):
        """è¿æ¥UIæš´éœ²çš„ä¿¡å·ï¼Œå°†é”™è¯¯å¤„ç†æ”¾åœ¨æ§åˆ¶å™¨ä¸­"""
        # ===== è¿æ¥è§†é¢‘æ’­æ”¾å™¨ä¿¡å· =====
        self.video_player.frame_ready.connect(self._on_player_frame)
        self.video_player.status_update.connect(self._on_status_update)
        self.video_player.progress_updated.connect(self._on_progress_updated)
        self.video_player.finished.connect(self._on_player_finished)
        
        # ===== è¿æ¥æŠ“å–å™¨ä¿¡å· =====
        self.frame_grabber.frame_processed.connect(self._on_frame_processed)
        self.frame_grabber.processing_complete.connect(self._on_processing_complete)
        self.frame_grabber.status_update.connect(self._on_status_update)
        self.frame_grabber.error_occurred.connect(self._on_grabber_error)
        self.frame_grabber.finished.connect(self._on_grabber_finished)
        
        # ===== æ–‡ä»¶èœå•ä¿¡å· =====
        self.ui.file_menu_init.connect(self._on_file_init)
        self.ui.file_menu_exit.connect(self._on_file_exit)
        
        # ===== å¸®åŠ©èœå•ä¿¡å· =====
        self.ui.help_menu_about.connect(self._on_help_about)
        self.ui.help_menu_manual.connect(self._on_help_manual)
        
        # ===== ä¸»è¦åŠŸèƒ½ä¿¡å· =====
        self.ui.model_load.connect(self.handle_load_model)
        self.ui.image_open.connect(self.handle_open_image)
        self.ui.video_open.connect(self.handle_open_video)
        self.ui.camera_open.connect(self.handle_open_camera)
        
        # ===== æ§åˆ¶æŒ‰é’®ä¿¡å· =====
        self.right_panel.start_inference.connect(self.handle_start_inference)
        self.right_panel.stop_inference.connect(self.handle_stop_inference)
        self.right_panel.save_screenshot.connect(self.handle_save_screenshot)
        
        # ===== å·¦ä¾§é¢æ¿æ’­æ”¾/æš‚åœä¿¡å· =====
        self.ui.left_panel_play_pause.connect(self.handle_play_pause)
        
        # ===== å·¦ä¾§é¢æ¿è¿›åº¦æ¡ä¿¡å· =====
        self.left_panel.progress_changed.connect(self.handle_progress_change)
        
        # ===== å‚æ•°ä¿¡å· =====
        self.right_panel.iou_changed.connect(self.handle_iou_change)
        self.right_panel.confidence_changed.connect(self.handle_confidence_change)
        self.right_panel.delay_changed.connect(self.handle_delay_change)
        self.right_panel.line_width_changed.connect(self.handle_line_width_change)
    
    # ============================================================================
    # ä¿¡å·å¤„ç†æ–¹æ³•
    # ============================================================================
    
    def _on_player_frame(self, q_image: QImage):
        """æ¥æ”¶åˆ°æ’­æ”¾å™¨çš„åŸå§‹å¸§ - ç›´æ¥æ˜¾ç¤ºï¼ˆæ— YOLOå¤„ç†æ—¶ï¼‰"""
        try:
            if not self.is_processing:
                pixmap = QPixmap.fromImage(q_image)
                self.left_panel.set_display_image(pixmap)
        except Exception as e:
            print(f"æ˜¾ç¤ºåŸå§‹å¸§å¤±è´¥: {e}")
    
    def _on_frame_processed(self, q_image: QImage):
        """æ¥æ”¶åˆ°å¤„ç†åçš„å¸§ - æ˜¾ç¤ºYOLOæ£€æµ‹ç»“æœ"""
        try:
            pixmap = QPixmap.fromImage(q_image)
            self.left_panel.set_display_image(pixmap)
        except Exception as e:
            print(f"æ˜¾ç¤ºå¤„ç†å¸§å¤±è´¥: {e}")
    
    def _on_player_finished(self):
        """æ’­æ”¾å™¨å®Œæˆ"""
        self.is_playing = False
        self.left_panel.set_play_state(False)
        print("æ’­æ”¾å™¨åœæ­¢")
    
    def _on_processing_complete(self, stats: dict):
        """å¤„ç†å®Œæˆ - æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        try:
            self.right_panel.update_statistics(
                detection_count=stats.get('detection_count', 0),
                confidence=stats.get('avg_confidence', 0.0),
                inference_time=stats.get('inference_time', 0),
                fps=stats.get('fps', 0.0)
            )
        except Exception as e:
            print(f"æ›´æ–°ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
    
    def _on_grabber_error(self, error_msg: str):
        """æŠ“å–å™¨é”™è¯¯"""
        print(f"æŠ“å–å™¨é”™è¯¯: {error_msg}")
    
    def _on_grabber_finished(self):
        """æŠ“å–å™¨å®Œæˆ"""
        self.is_processing = False
        self.right_panel.set_control_state(False)
        print("å¸§æŠ“å–åœæ­¢")
    
    def _on_status_update(self, status: str):
        """çŠ¶æ€æ›´æ–°"""
        print(f"çŠ¶æ€: {status}")
    
    def _on_progress_updated(self, current_frame, total_frames, current_time):
        """è§†é¢‘è¿›åº¦æ›´æ–°"""
        try:
            if self.current_mode == 'video':
                self.left_panel.set_progress_range(0, 1000)
                
                if total_frames > 0:
                    progress_value = int((current_frame / total_frames) * 1000)
                    self.left_panel.set_progress_value(progress_value)
                
                current_time_str = self._format_time(current_time)
                total_time_str = self._format_time(total_frames / self.video_player.fps) if self.video_player.fps > 0 else "--:--"
                self.left_panel.set_time_display(current_time_str, total_time_str)
                
        except Exception as e:
            print(f"æ›´æ–°è¿›åº¦å¤±è´¥: {e}")
    
    def handle_progress_change(self, value):
        """ç”¨æˆ·æ‹–åŠ¨è¿›åº¦æ¡"""
        if self.current_mode == 'video' and hasattr(self.video_player, 'cap') and self.video_player.cap:
            try:
                total_frames = self.video_player.total_frames
                if total_frames > 0:
                    target_frame = int((value / 1000.0) * total_frames)
                    self.video_player.seek_frame(target_frame)
                    
                    print(f"è·³è½¬åˆ°è¿›åº¦: {value}/1000, å¸§å·: {target_frame}/{total_frames}")
            except Exception as e:
                print(f"è·³è½¬è¿›åº¦å¤±è´¥: {e}")
    
    def handle_play_pause(self):
        """æ’­æ”¾/æš‚åœæŒ‰é’®ç‚¹å‡»"""
        try:
            if self.current_mode == 'video':
                if self.video_player.playing:
                    self.video_player.pause()
                    self.left_panel.set_play_state(False)
                else:
                    self.video_player.resume()
                    self.left_panel.set_play_state(True)
            elif self.current_mode == 'camera':
                if self.video_player.playing:
                    self.video_player.pause()
                    self.left_panel.set_play_state(False)
                else:
                    self.video_player.resume()
                    self.left_panel.set_play_state(True)
        except Exception as e:
            print(f"æ’­æ”¾/æš‚åœå¤±è´¥: {e}")
    
    # ============================================================================
    # æ–‡ä»¶èœå•å¤„ç†æ–¹æ³•
    # ============================================================================
    
    def _on_file_init(self):
        """åˆå§‹åŒ–"""
        reply = QMessageBox.question(
            self.ui, "ç¡®è®¤åˆå§‹åŒ–",
            "æ˜¯å¦è¦åˆå§‹åŒ–æ‰€æœ‰è®¾ç½®ï¼Ÿ",
            QMessageBox.Yes | QMessageBox.No,
            QMessageBox.No
        )
        
        if reply == QMessageBox.Yes:
            self._stop_all()
            self._init_ui_state()
            QMessageBox.information(self.ui, "åˆå§‹åŒ–å®Œæˆ", "æ‰€æœ‰è®¾ç½®å·²é‡ç½®")
    
    def _on_file_exit(self):
        """é€€å‡º"""
        reply = QMessageBox.question(
            self.ui, "ç¡®è®¤é€€å‡º",
            "æ˜¯å¦è¦é€€å‡ºYOLOæ£€æµ‹ç³»ç»Ÿï¼Ÿ",
            QMessageBox.Yes | QMessageBox.No,
            QMessageBox.No
        )
        
        if reply == QMessageBox.Yes:
            self._stop_all()
            self.ui.close()
    
    # ============================================================================
    # å¸®åŠ©èœå•å¤„ç†æ–¹æ³•
    # ============================================================================
    
    def _on_help_about(self):
        """æ˜¾ç¤ºå…³äºå¯¹è¯æ¡†"""
        about_text = f"""
        <h3>YOLOå¤šåŠŸèƒ½æ£€æµ‹ç³»ç»Ÿ</h3>
        
        <b>ç‰ˆæœ¬:</b> 1.0.0<br>
        <b>ä½œè€…:</b> Sephoration<br><br>
        
        <b>åŠŸèƒ½ç‰¹ç‚¹:</b><br>
        â€¢ ç›®æ ‡æ£€æµ‹ä¸è·Ÿè¸ª<br>
        â€¢ å…³é”®ç‚¹/å§¿æ€æ£€æµ‹<br>
        â€¢ å›¾åƒåˆ†ç±»<br>
        â€¢ æ”¯æŒå›¾ç‰‡ã€è§†é¢‘ã€æ‘„åƒå¤´<br>
        â€¢ å®æ—¶ç»Ÿè®¡ä¸å¯è§†åŒ–<br><br>
        
        <b>æŠ€æœ¯æ”¯æŒ:</b><br>
        â€¢ PySide6 (Qt for Python)<br>
        â€¢ Ultralytics YOLO<br>
        â€¢ OpenCV<br><br>
        
        <b>Â© 2024 ç‰ˆæƒæ‰€æœ‰</b>
        """
        
        QMessageBox.about(self.ui, "å…³äº", about_text)
    
    def _on_help_manual(self):
        """æ˜¾ç¤ºä½¿ç”¨è¯´æ˜"""
        manual_text = """
        <h3>YOLOå¤šåŠŸèƒ½æ£€æµ‹ç³»ç»Ÿ - ä½¿ç”¨è¯´æ˜</h3>
        
        <b>1. åŠ è½½æ¨¡å‹</b><br>
        â€¢ ç‚¹å‡»"æ‰“å¼€æ¨¡å‹"æŒ‰é’®é€‰æ‹©YOLOæ¨¡å‹æ–‡ä»¶ (.pt)<br>
        â€¢ é€‰æ‹©å¯¹åº”çš„æ¨¡å—ç±»å‹ï¼šåˆ†æå™¨(ç›®æ ‡æ£€æµ‹)ã€åˆ†ç±»å™¨ã€å…³é”®ç‚¹æ£€æµ‹<br><br>
        
        <b>2. æ‰“å¼€åª’ä½“æ–‡ä»¶</b><br>
        â€¢ <b>å›¾ç‰‡</b>: ç‚¹å‡»"æ‰“å¼€å›¾ç‰‡"ï¼Œé€‰æ‹©å›¾ç‰‡æ–‡ä»¶<br>
        â€¢ <b>è§†é¢‘</b>: ç‚¹å‡»"æ‰“å¼€è§†é¢‘"ï¼Œé€‰æ‹©è§†é¢‘æ–‡ä»¶<br>
        â€¢ <b>æ‘„åƒå¤´</b>: ç‚¹å‡»"æ‰“å¼€æ‘„åƒå¤´"ï¼Œä½¿ç”¨é»˜è®¤æ‘„åƒå¤´<br><br>
        
        <b>3. å‚æ•°è®¾ç½®</b><br>
        â€¢ <b>IOUé˜ˆå€¼</b>: æ§åˆ¶æ£€æµ‹æ¡†é‡å åº¦ (0.0-1.0)<br>
        â€¢ <b>ç½®ä¿¡åº¦</b>: è¿‡æ»¤ä½ç½®ä¿¡åº¦æ£€æµ‹ç»“æœ (0.0-1.0)<br>
        â€¢ <b>å»¶è¿Ÿ(ms)</b>: æ§åˆ¶å¤„ç†é—´éš”ï¼Œå½±å“å®æ—¶æ€§<br>
        â€¢ <b>çº¿å®½</b>: è°ƒæ•´æ£€æµ‹æ¡†å’Œå…³é”®ç‚¹çš„ç»˜åˆ¶çº¿å®½<br><br>
        
        <b>4. å¼€å§‹æ£€æµ‹</b><br>
        â€¢ ç‚¹å‡»"å¼€å§‹"æŒ‰é’®å¼€å§‹æ¨ç†å¤„ç†<br>
        â€¢ å®æ—¶ç»Ÿè®¡é¢æ¿æ˜¾ç¤ºå¤„ç†ç»“æœ<br>
        â€¢ ç‚¹å‡»"åœæ­¢"æŒ‰é’®ç»“æŸå¤„ç†<br><br>
        
        <b>5. è§†é¢‘æ§åˆ¶</b><br>
        â€¢ <b>æ’­æ”¾/æš‚åœ</b>: æ§åˆ¶è§†é¢‘æ’­æ”¾<br>
        â€¢ <b>è¿›åº¦æ¡</b>: æ‹–åŠ¨è·³è½¬åˆ°æŒ‡å®šä½ç½®<br>
        â€¢ <b>æ—¶é—´æ˜¾ç¤º</b>: æ˜¾ç¤ºå½“å‰/æ€»æ—¶é•¿<br><br>
        
        <b>6. å…¶ä»–åŠŸèƒ½</b><br>
        â€¢ <b>ä¿å­˜æˆªå›¾</b>: ä¿å­˜å½“å‰æ˜¾ç¤ºç”»é¢<br>
        â€¢ <b>åˆå§‹åŒ–</b>: é‡ç½®æ‰€æœ‰è®¾ç½®<br>
        â€¢ <b>é€€å‡º</b>: å…³é—­åº”ç”¨ç¨‹åº<br><br>
        
        <b>æç¤º:</b><br>
        â€¢ ç¡®ä¿å·²å®‰è£…å¿…è¦çš„Pythonåº“<br>
        â€¢ ä½¿ç”¨åˆé€‚çš„YOLOæ¨¡å‹æ–‡ä»¶<br>
        â€¢ è°ƒæ•´å‚æ•°ä»¥è·å¾—æœ€ä½³æ£€æµ‹æ•ˆæœ
        """
        
        QMessageBox.information(self.ui, "ä½¿ç”¨è¯´æ˜", manual_text)
    
    # ============================================================================
    # ä¸»è¦åŠŸèƒ½å¤„ç†æ–¹æ³•
    # ============================================================================
    
    def handle_load_model(self):
        """åŠ è½½æ¨¡å‹"""
        try:
            # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ–‡ä»¶è¿‡æ»¤å™¨
            model_filter = AppConfig.FILE_SETTINGS['file_filters']['model']
            model_path, _ = QFileDialog.getOpenFileName(
                self.ui, "é€‰æ‹©YOLOæ¨¡å‹æ–‡ä»¶",
                "", model_filter
            )
            
            if model_path:
                # æ¸…ç©ºä¹‹å‰çš„æ¨¡å‹ä¿¡æ¯
                self.model_path = None
                self.model_mode = None
                self.yolo_processor = None
                self.model_loaded = False
                
                print(f"å¼€å§‹åˆ†ææ¨¡å‹: {model_path}")
                
                try:
                    # ä½¿ç”¨UnifiedYOLOåˆ†ææ¨¡å‹ï¼ˆä¸åŠ è½½å®Œæ•´æ¨¡å‹ï¼‰
                    from yolo_analyzer import UnifiedYOLO
                    
                    # åˆ†ææ¨¡å‹ä¿¡æ¯ï¼ˆè½»é‡çº§åˆ†æï¼Œä¸çœŸæ­£åŠ è½½æ¨¡å‹ï¼‰
                    model_info = UnifiedYOLO.analyze_model_info(model_path)
                    
                    if model_info:
                        # è·å–æ¨¡å‹ä¿¡æ¯
                        model_name = os.path.basename(model_path)
                        task_type = model_info.get('task_type', 'detection')
                        input_size = model_info.get('input_size', '640x640')
                        class_count = model_info.get('class_count', 'æœªçŸ¥')
                        
                        # ä»»åŠ¡ç±»å‹åˆ°æ˜¾ç¤ºåç§°æ˜ å°„
                        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„ä»»åŠ¡æ˜¾ç¤ºæ˜ å°„
                        task_display_map = AppConfig.TASK_CONFIG['task_display_map']
                        
                        display_name = task_display_map.get(task_type, task_type)
                        self.model_mode = task_type
                        
                        # æ›´æ–°UIæ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
                        self.right_panel.update_model_info(
                            model_path=model_path,
                            task_type=display_name,
                            input_size=input_size,
                            class_count=class_count
                        )
                        
                        self.model_path = model_path
                        
                        # æ˜¾ç¤ºæˆåŠŸä¿¡æ¯
                        QMessageBox.information(
                            self.ui, "æ¨¡å‹åˆ†ææˆåŠŸ",
                            f"âœ… å·²è‡ªåŠ¨è¯†åˆ«æ¨¡å‹ç±»å‹\n\n"
                            f"ğŸ“¦ æ¨¡å‹åç§°: {model_name}\n"
                            f"ğŸ¯ ä»»åŠ¡ç±»å‹: {display_name}\n"
                            f"ğŸ“ è¾“å…¥å°ºå¯¸: {input_size}\n"
                            f"ğŸ”¢ ç±»åˆ«æ•°é‡: {class_count}\n\n"
                            f"æ¨¡å‹å°†åœ¨ç‚¹å‡»'å¼€å§‹'æ—¶æ­£å¼åŠ è½½ã€‚"
                        )
                        
                        print(f"æ¨¡å‹åˆ†æå®Œæˆï¼Œç±»å‹: {task_type}")
                    else:
                        raise Exception("æ— æ³•è¯†åˆ«æ¨¡å‹ç±»å‹")
                    
                except Exception as e:
                    print(f"æ¨¡å‹åˆ†æå¤±è´¥: {e}")
                    # åˆ†æå¤±è´¥ï¼Œè®©ç”¨æˆ·é€‰æ‹©æ¨¡å‹ç±»å‹
                    self._show_model_type_dialog(model_path)
                    
        except Exception as e:
            self._show_error("é€‰æ‹©æ¨¡å‹å¤±è´¥", str(e))
    
    def _show_model_type_dialog(self, model_path):
        """æ˜¾ç¤ºæ¨¡å‹ç±»å‹é€‰æ‹©å¯¹è¯æ¡†"""
        try:
            from PySide6.QtWidgets import QDialog, QVBoxLayout, QPushButton, QLabel
            from PySide6.QtCore import Qt
            
            dialog = QDialog(self.ui)
            dialog.setWindowTitle("é€‰æ‹©æ¨¡å‹ç±»å‹")
            dialog.setFixedSize(300, 220)
            
            layout = QVBoxLayout(dialog)
            layout.setContentsMargins(20, 20, 20, 20)
            layout.setSpacing(15)
            
            model_name = os.path.basename(model_path)
            info_label = QLabel(f"å·²é€‰æ‹©æ¨¡å‹:\n{model_name}")
            info_label.setAlignment(Qt.AlignCenter)
            layout.addWidget(info_label)
            
            tip_label = QLabel("è¯·é€‰æ‹©å¤„ç†æ¨¡å¼:")
            tip_label.setAlignment(Qt.AlignCenter)
            layout.addWidget(tip_label)
            
            btn_detect = QPushButton("ç›®æ ‡æ£€æµ‹")
            btn_classify = QPushButton("å›¾åƒåˆ†ç±»")
            btn_pose = QPushButton("å…³é”®ç‚¹æ£€æµ‹")
            
            button_style = """
                QPushButton {
                    background-color: #f0f0f0;
                    border: 1px solid #cccccc;
                    border-radius: 4px;
                    padding: 10px;
                    font-weight: normal;
                    min-height: 40px;
                }
                QPushButton:hover {
                    background-color: #e0e0e0;
                    border-color: #aaaaaa;
                }
            """
            
            for btn in [btn_detect, btn_classify, btn_pose]:
                btn.setStyleSheet(button_style)
            
            btn_detect.clicked.connect(lambda: self._select_model_type('detection', model_path, dialog))
            btn_classify.clicked.connect(lambda: self._select_model_type('classification', model_path, dialog))
            btn_pose.clicked.connect(lambda: self._select_model_type('pose', model_path, dialog))
            
            layout.addWidget(btn_detect)
            layout.addWidget(btn_classify)
            layout.addWidget(btn_pose)
            
            dialog.exec()
            
        except Exception as e:
            self._show_error("é€‰æ‹©æ¨¡å‹ç±»å‹å¤±è´¥", str(e))
    
    def _select_model_type(self, model_type: str, model_path: str, dialog):
        """é€‰æ‹©æ¨¡å‹ç±»å‹"""
        try:
            self.model_mode = model_type
            self.model_path = model_path
            
            # ä»»åŠ¡ç±»å‹åˆ°æ˜¾ç¤ºåç§°æ˜ å°„
            # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„ä»»åŠ¡æ˜¾ç¤ºæ˜ å°„
            task_display_map = AppConfig.TASK_CONFIG['task_display_map']
            
            display_name = task_display_map.get(model_type, model_type)
            
            # æ›´æ–°UIæ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
            self.right_panel.update_model_info(
                model_path=model_path,
                task_type=display_name,
                input_size="640x640",  # é»˜è®¤å°ºå¯¸
                class_count="å¾…æ£€æµ‹"
            )
            
            # æ˜¾ç¤ºæˆåŠŸä¿¡æ¯
            QMessageBox.information(
                self.ui, "æ¨¡å‹é€‰æ‹©æˆåŠŸ",
                f"âœ… å·²é€‰æ‹©{display_name}æ¨¡å¼\n\n"
                f"ğŸ“¦ æ¨¡å‹: {os.path.basename(model_path)}\n"
                f"ğŸ¯ ä»»åŠ¡: {display_name}\n\n"
                f"æ¨¡å‹å°†åœ¨ç‚¹å‡»'å¼€å§‹'æ—¶æ­£å¼åŠ è½½ã€‚"
            )
            
            print(f"å·²é€‰æ‹©{display_name}æ¨¡å¼ï¼Œæ¨¡å‹å°†åœ¨ç‚¹å‡»'å¼€å§‹'æ—¶åŠ è½½")
            
            dialog.close()
            
        except Exception as e:
            self._show_error("é€‰æ‹©æ¨¡å—å¤±è´¥", str(e))
    
    def handle_open_image(self):
        """æ‰“å¼€å›¾ç‰‡"""
        try:
            self._stop_all()
            
            # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ–‡ä»¶è¿‡æ»¤å™¨
            image_filter = AppConfig.FILE_SETTINGS['file_filters']['image']
            image_path, _ = QFileDialog.getOpenFileName(
                self.ui, "é€‰æ‹©å›¾ç‰‡æ–‡ä»¶",
                "", image_filter
            )
            
            if image_path:
                self.current_file = image_path
                self.current_mode = 'image'
                
                self.left_panel.update_info(os.path.basename(image_path), 'image')
                
                pixmap = QPixmap(image_path)
                if not pixmap.isNull():
                    self.left_panel.set_display_image(pixmap)
                    print(f"å·²åŠ è½½å›¾ç‰‡: {os.path.basename(image_path)}")
                else:
                    QMessageBox.warning(self.ui, "è­¦å‘Š", "æ— æ³•åŠ è½½å›¾ç‰‡æ–‡ä»¶")
                
        except Exception as e:
            self._show_error("æ‰“å¼€å›¾ç‰‡å¤±è´¥", str(e))
    
    def handle_open_video(self):
        """æ‰“å¼€è§†é¢‘"""
        try:
            self._stop_all()

            # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ–‡ä»¶è¿‡æ»¤å™¨
            video_filter = AppConfig.FILE_SETTINGS['file_filters']['video']
            video_path, _ = QFileDialog.getOpenFileName(
                self.ui, "é€‰æ‹©è§†é¢‘æ–‡ä»¶",
                "", video_filter
            )

            if video_path:
                self.current_file = video_path
                self.current_mode = 'video'
                self.is_playing = True

                self.left_panel.update_info(os.path.basename(video_path), 'video')

                # ä½¿ç”¨VideoPlayerThread (QThreadç‰ˆæœ¬)
                self.video_player.play_video(video_path)
                self.left_panel.set_play_state(True)  # è®¾ç½®æ’­æ”¾çŠ¶æ€

            print(f"å¼€å§‹æ’­æ”¾è§†é¢‘: {os.path.basename(video_path)}")
                
        except Exception as e:
            self._show_error("æ‰“å¼€è§†é¢‘å¤±è´¥", str(e))

    def handle_open_camera(self):
        """æ‰“å¼€æ‘„åƒå¤´"""
        try:
            self._stop_all()

            camera_id = 0  # é»˜è®¤æ‘„åƒå¤´

            self.current_file = f"æ‘„åƒå¤´ {camera_id}"
            self.current_mode = 'camera'
            self.is_playing = True

            self.left_panel.update_info(f"æ‘„åƒå¤´ {camera_id}", 'camera')

            # ä½¿ç”¨VideoPlayerThread (QThreadç‰ˆæœ¬)
            self.video_player.play_camera(camera_id)
            self.left_panel.set_play_state(True)  # è®¾ç½®æ’­æ”¾çŠ¶æ€

            print(f"å¼€å§‹æ‘„åƒå¤´å®æ—¶æ˜¾ç¤º")
                
        except Exception as e:
            self._show_error("æ‰“å¼€æ‘„åƒå¤´å¤±è´¥", str(e))
        
    # ============================================================================
    # æ§åˆ¶æŒ‰é’®å¤„ç†æ–¹æ³•
    # ============================================================================
    
    def handle_start_inference(self):
        """å¼€å§‹æ¨ç†"""
        try:
            # æ£€æŸ¥å¿…è¦æ¡ä»¶
            if not self.current_file:
                QMessageBox.warning(self.ui, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©åª’ä½“æ–‡ä»¶ï¼")
                return
            
            if not self.model_path or not self.model_mode:
                QMessageBox.warning(self.ui, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©æ¨¡å‹ï¼")
                return
            
            # åŠ è½½æ¨¡å‹ï¼ˆæ­¤æ—¶æ‰çœŸæ­£åŠ è½½ï¼‰
            if not self._load_yolo_processor():
                return
            
            # æ£€æŸ¥å½“å‰æ¨¡å¼
            if self.current_mode == 'image':
                self._process_image()
            elif self.current_mode in ['video', 'camera']:
                self._process_video_camera()
            else:
                QMessageBox.warning(self.ui, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©åª’ä½“æ–‡ä»¶ï¼")
                
        except Exception as e:
            self._show_error("å¼€å§‹å¤„ç†å¤±è´¥", str(e))
    
    def _process_image(self):
        """å¤„ç†å›¾ç‰‡"""
        try:
            if not self._load_yolo_processor():
                return
            
            print(f"å¼€å§‹å¤„ç†å›¾ç‰‡: {self.current_file}")
            
            # åŠ è½½å›¾ç‰‡
            import cv2
            from PySide6.QtGui import QImage, QPixmap
            
            image = cv2.imread(self.current_file)
            if image is None:
                QMessageBox.warning(self.ui, "è­¦å‘Š", "æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶")
                return
            
            # è°ƒç”¨YOLOå¤„ç†å™¨å¤„ç†å›¾ç‰‡
            result_dict = self.yolo_processor.process_frame(image)
            
            # æå–å¤„ç†åçš„å›¾åƒå’Œç»Ÿè®¡ä¿¡æ¯
            if isinstance(result_dict, dict):
                processed_image = result_dict.get('image', image)
                stats_data = result_dict.get('stats', {})
            else:
                processed_image = image
                stats_data = {}
                print("è­¦å‘Š: YOLOå¤„ç†å™¨è¿”å›çš„ä¸æ˜¯å­—å…¸æ ¼å¼")
            
            # æ˜¾ç¤ºå¤„ç†åçš„å›¾åƒ
            if isinstance(processed_image, type(image)):  # æ£€æŸ¥æ˜¯å¦æ˜¯numpyæ•°ç»„
                # ç¡®ä¿å›¾åƒæ˜¯RGBæ ¼å¼
                if len(processed_image.shape) == 2:  # ç°åº¦å›¾
                    processed_rgb = cv2.cvtColor(processed_image, cv2.COLOR_GRAY2RGB)
                elif processed_image.shape[2] == 4:  # RGBA
                    processed_rgb = cv2.cvtColor(processed_image, cv2.COLOR_BGRA2RGB)
                else:  # BGR
                    processed_rgb = cv2.cvtColor(processed_image, cv2.COLOR_BGR2RGB)
                
                height, width, channel = processed_rgb.shape
                bytes_per_line = 3 * width
                
                q_img = QImage(processed_rgb.data, width, height, 
                              bytes_per_line, QImage.Format_RGB888)
                pixmap = QPixmap.fromImage(q_img)
                self.left_panel.set_display_image(pixmap)
            else:
                print(f"è­¦å‘Š: å¤„ç†åçš„å›¾åƒä¸æ˜¯numpyæ•°ç»„ï¼Œç±»å‹: {type(processed_image)}")
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.right_panel.update_statistics(
                detection_count=stats_data.get('detection_count', 0),
                confidence=stats_data.get('avg_confidence', 0.0),
                inference_time=stats_data.get('inference_time', 0),
                fps=stats_data.get('fps', 0.0)
            )
            
            # æ›´æ–°UIçŠ¶æ€
            self.right_panel.set_control_state(True)
            self.is_processing = True
            
            print(f"å›¾ç‰‡å¤„ç†å®Œæˆ: {self.current_file}")
            
        except Exception as e:
            self._show_error("å›¾ç‰‡å¤„ç†å¤±è´¥", str(e))
    
    def _process_video_camera(self):
        """å¤„ç†è§†é¢‘/æ‘„åƒå¤´"""
        try:
            if not self._load_yolo_processor():
                return
            
            # è®¾ç½®YOLOå¤„ç†å™¨åˆ°æŠ“å–å™¨
            self.frame_grabber.set_yolo_processor(self.yolo_processor)
            
            # è·å–æŠ“å–é—´éš”å‚æ•°
            delay_ms = self.right_panel.get_parameters().get('delay_ms', 10)
            grab_interval = max(1, delay_ms // 10)  # æ ¹æ®å»¶è¿Ÿè®¡ç®—é—´éš”
            
            # å¼€å§‹æŠ“å–å¸§
            self.frame_grabber.start_grabbing(grab_interval)
            
            # æ›´æ–°UIçŠ¶æ€
            self.right_panel.set_control_state(True)
            self.is_processing = True
            
            print(f"å¼€å§‹å¤„ç†{self.current_mode}: {self.current_file}")
            print(f"æŠ“å–é—´éš”: æ¯{grab_interval}å¸§æŠ“å–ä¸€æ¬¡")
            
        except Exception as e:
            self._show_error("å¼€å§‹å¤„ç†å¤±è´¥", str(e))
    
    def _load_yolo_processor(self) -> bool:
        """åŠ è½½YOLOå¤„ç†å™¨ï¼ˆåœ¨ç‚¹å‡»"å¼€å§‹"æ—¶è°ƒç”¨ï¼‰"""
        try:
            if not self.model_path or not self.model_mode:
                QMessageBox.warning(self.ui, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©æ¨¡å‹ï¼")
                return False
            
            if self.yolo_processor is not None:
                print("YOLOå¤„ç†å™¨å·²åŠ è½½ï¼Œè·³è¿‡é‡å¤åŠ è½½")
                return True
            
            # è·å–å‚æ•°
            params = self.right_panel.get_parameters()
            
            print(f"æ­£åœ¨æ­£å¼åŠ è½½YOLOæ¨¡å‹: {self.model_path}")
            print(f"æ¨¡å¼: {self.model_mode}")
            print(f"å‚æ•°: IOU={params['iou_threshold']}, ç½®ä¿¡åº¦={params['confidence_threshold']}")
            
            # åˆ›å»ºYOLOå¤„ç†å™¨å®ä¾‹
            from yolo_analyzer import UnifiedYOLO
            self.yolo_processor = UnifiedYOLO(
                model_path=self.model_path,
                mode=self.model_mode,
                conf_threshold=params['confidence_threshold'],
                iou_threshold=params['iou_threshold']
            )
            
            self.model_loaded = True
            
            # è·å–æ¨¡å‹ä¿¡æ¯
            model_info = self.yolo_processor.get_model_info()
            
            # æ›´æ–°UIæ˜¾ç¤ºè¯¦ç»†æ¨¡å‹ä¿¡æ¯
            # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„ä»»åŠ¡æ˜¾ç¤ºæ˜ å°„
            task_display_map = AppConfig.TASK_CONFIG['task_display_map']
            
            display_name = task_display_map.get(self.model_mode, self.model_mode)
            input_size_str = f"{model_info.get('input_size', 640)}"
            # åŒæ—¶å°è¯•class_countå’Œnum_classesé”®ï¼Œç¡®ä¿èƒ½è·å–åˆ°ç±»åˆ«æ•°é‡
            class_count = model_info.get('class_count', model_info.get('num_classes', 'æœªçŸ¥'))
            
            self.right_panel.update_model_info(
                model_path=self.model_path,
                task_type=display_name,
                input_size=input_size_str,
                class_count=str(class_count)
            )
            
            print(f"âœ… YOLOå¤„ç†å™¨åŠ è½½æˆåŠŸ: {self.model_mode}")
            print(f"   - è¾“å…¥å°ºå¯¸: {input_size_str}")
            print(f"   - ç±»åˆ«æ•°é‡: {class_count}")
            return True
                
        except Exception as e:
            self._show_error("åŠ è½½YOLOå¤„ç†å™¨å¤±è´¥", str(e))
            self.model_loaded = False
            return False
    
    def handle_stop_inference(self):
        """åœæ­¢æ¨ç†"""
        self._stop_processing()
    
    def handle_save_screenshot(self):
        """ä¿å­˜æˆªå›¾"""
        try:
            pixmap = self.left_panel.display_label.pixmap()
            if pixmap and not pixmap.isNull():
                # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ–‡ä»¶è¿‡æ»¤å™¨
                file_filter = AppConfig.FILE_SETTINGS['file_filters']['screenshot']
                
                if self.current_file:
                    base_name = os.path.splitext(os.path.basename(self.current_file))[0]
                else:
                    base_name = "screenshot"
                
                default_name = f"{base_name}.png"
                
                save_path, _ = QFileDialog.getSaveFileName(
                    self.ui, "ä¿å­˜æˆªå›¾",
                    default_name,
                    file_filter
                )
                
                if save_path:
                    if not save_path.lower().endswith(('.png', '.jpg', '.jpeg')):
                        save_path += '.png'
                    
                    success = pixmap.save(save_path)
                    if success:
                        QMessageBox.information(self.ui, "ä¿å­˜æˆåŠŸ", f"æˆªå›¾å·²ä¿å­˜åˆ°:\n{save_path}")
                        print(f"æˆªå›¾ä¿å­˜åˆ°: {save_path}")
                    else:
                        QMessageBox.warning(self.ui, "ä¿å­˜å¤±è´¥", "æ— æ³•ä¿å­˜æˆªå›¾")
            else:
                QMessageBox.warning(self.ui, "è­¦å‘Š", "æ²¡æœ‰å¯ä¿å­˜çš„å›¾åƒ")
                
        except Exception as e:
            self._show_error("ä¿å­˜æˆªå›¾å¤±è´¥", str(e))
    
    # ============================================================================
    # è¾…åŠ©æ–¹æ³•
    # ============================================================================
    
    def _stop_all(self):
        """åœæ­¢æ‰€æœ‰å¤„ç†"""
        self._stop_processing()
        self.video_player.stop()
        self.is_playing = False
        self.left_panel.set_controls_enabled(False)
    
    def _stop_processing(self):
        """åœæ­¢å¤„ç†"""
        self.frame_grabber.stop_grabbing()
        self.is_processing = False
        self.right_panel.set_control_state(False)
        print("å¤„ç†å·²åœæ­¢")
    
    def _format_time(self, seconds):
        """æ ¼å¼åŒ–æ—¶é—´ä¸º MM:SS æ ¼å¼"""
        try:
            minutes = int(seconds // 60)
            secs = int(seconds % 60)
            return f"{minutes:02d}:{secs:02d}"
        except:
            return "--:--"
    
    def _show_error(self, title: str, message: str):
        """æ˜¾ç¤ºé”™è¯¯"""
        QMessageBox.critical(
            self.ui, title,
            f"{message}\n\nè¯¦ç»†ä¿¡æ¯è¯·æŸ¥çœ‹æ§åˆ¶å°è¾“å‡ºã€‚"
        )
        print(f"é”™è¯¯ [{title}]: {message}")
        traceback.print_exc()
    
    def handle_iou_change(self, value):
        """å¤„ç†IOUé˜ˆå€¼å˜åŒ–"""
        try:
            self.default_params['iou_threshold'] = value
            print(f"IOUé˜ˆå€¼å·²æ›´æ–°: {value}")
            # å¦‚æœæ¨¡å‹å·²åŠ è½½ï¼Œæ›´æ–°æ¨¡å‹å‚æ•°
            if hasattr(self, 'yolo_processor') and self.yolo_processor is not None:
                success = self.yolo_processor.update_params(iou_threshold=value)
                if success:
                    print("IOUå‚æ•°æ›´æ–°æˆåŠŸ")
                else:
                    print("IOUå‚æ•°æ›´æ–°å¤±è´¥")
        except Exception as e:
            self._show_error("æ›´æ–°IOUé˜ˆå€¼å¤±è´¥", str(e))
    
    def handle_confidence_change(self, value):
        """å¤„ç†ç½®ä¿¡åº¦é˜ˆå€¼å˜åŒ–"""
        try:
            self.default_params['confidence_threshold'] = value
            print(f"ç½®ä¿¡åº¦é˜ˆå€¼å·²æ›´æ–°: {value}")
            # å¦‚æœæ¨¡å‹å·²åŠ è½½ï¼Œæ›´æ–°æ¨¡å‹å‚æ•°
            if hasattr(self, 'yolo_processor') and self.yolo_processor is not None:
                success = self.yolo_processor.update_params(conf_threshold=value)
                if success:
                    print("ç½®ä¿¡åº¦å‚æ•°æ›´æ–°æˆåŠŸ")
                else:
                    print("ç½®ä¿¡åº¦å‚æ•°æ›´æ–°å¤±è´¥")
        except Exception as e:
            self._show_error("æ›´æ–°ç½®ä¿¡åº¦é˜ˆå€¼å¤±è´¥", str(e))
    
    def handle_delay_change(self, value):
        """å¤„ç†å»¶è¿Ÿæ—¶é—´å˜åŒ–"""
        try:
            self.default_params['delay_ms'] = value
            print(f"å»¶è¿Ÿæ—¶é—´å·²æ›´æ–°: {value}ms")
        except Exception as e:
            self._show_error("æ›´æ–°å»¶è¿Ÿæ—¶é—´å¤±è´¥", str(e))
    
    def handle_line_width_change(self, value):
        """å¤„ç†çº¿å®½å˜åŒ–"""
        try:
            self.default_params['line_width'] = value
            print(f"çº¿å®½å·²æ›´æ–°: {value}")
            # å¦‚æœæ¨¡å‹å·²åŠ è½½ï¼Œæ›´æ–°æ¨¡å‹å‚æ•°
            if self.yolo_processor:
                self.yolo_processor.update_params(line_width=value)
        except Exception as e:
            self._show_error("æ›´æ–°çº¿å®½å¤±è´¥", str(e))