"""
é€»è¾‘æ§åˆ¶å™¨
ä½¿ç”¨Qtä¿¡å·æ§½è¿æ¥æ’­æ”¾å™¨ã€æ¨ç†å™¨å’ŒUI
"""

import os
import sys
import time
import traceback
from pathlib import Path
from typing import Dict, Any, Optional

from PySide6.QtCore import QObject, Signal, Qt, QThread, QTimer, QMutex, QWaitCondition, Slot
from PySide6.QtGui import QPixmap, QImage
from PySide6.QtWidgets import QMessageBox, QFileDialog

from window_ui import YOLOMainWindowUI
from detector_worker import DetectorWorker
from yolo_analyzer import UnifiedYOLO
from config import AppConfig


class VideoPlayerThread(QThread):
    """
    ç®€åŒ–ç‰ˆè§†é¢‘æ’­æ”¾å™¨
    åªè´Ÿè´£è§£ç å’Œå‘é€å¸§ï¼Œç§»é™¤æ‰€æœ‰ä¸å¿…è¦çš„é”
    """
    
    # ä¿¡å·å®šä¹‰
    display_frame_ready = Signal(QImage)  # æ˜¾ç¤ºå¸§ â†’ UI
    raw_frame_ready = Signal(object)      # åŸå§‹å¸§ â†’ æ¨ç†å™¨ï¼ˆä½¿ç”¨objectç±»å‹é¿å…numpyå¯¼å…¥é—®é¢˜ï¼‰
    status_updated = Signal(str)          # çŠ¶æ€æ›´æ–°
    playback_finished = Signal()          # æ’­æ”¾å®Œæˆ
    
    def __init__(self):
        super().__init__()
        
        # æ’­æ”¾æ§åˆ¶
        self._is_running = False
        self._is_paused = False
        self._stop_requested = False
        
        # è§†é¢‘/æ‘„åƒå¤´
        self.cap = None
        self.video_path = None
        self.camera_id = None
        self.play_mode = None  # 'video' or 'camera'
        
        # è§†é¢‘ä¿¡æ¯
        self.total_frames = 0
        self.current_frame_num = 0
        self.fps = AppConfig.VIDEO_SETTINGS['min_fps']
        self.duration = 0.0
        
        # å¸§ç¼“å­˜
        self.current_frame = None
        
        # ç®€å•çš„äº’æ–¥é”ï¼ˆä»…ç”¨äºçŠ¶æ€ä¿æŠ¤ï¼‰
        self.mutex = QMutex()
        
        # æ³¨æ„ï¼šä¸åœ¨__init__ä¸­åˆ›å»ºQTimerï¼Œåœ¨run()ä¸­åˆ›å»º
    
    def play_video(self, video_path: str):
        """æ’­æ”¾è§†é¢‘æ–‡ä»¶"""
        self.stop()
        
        self.mutex.lock()
        try:
            self.video_path = video_path
            self.camera_id = None
            self.play_mode = 'video'
            self._is_running = True
            self._is_paused = False
            self._stop_requested = False
            
            if not self.isRunning():
                self.start()
            else:
                # çº¿ç¨‹å·²åœ¨è¿è¡Œï¼Œå¼€å§‹æ’­æ”¾
                self._setup_video()
                
        finally:
            self.mutex.unlock()
    
    def play_camera(self, camera_id: int = 0):
        """æ’­æ”¾æ‘„åƒå¤´"""
        self.stop()
        
        self.mutex.lock()
        try:
            self.video_path = None
            self.camera_id = camera_id
            self.play_mode = 'camera'
            self._is_running = True
            self._is_paused = False
            self._stop_requested = False
            
            if not self.isRunning():
                self.start()
            else:
                # çº¿ç¨‹å·²åœ¨è¿è¡Œï¼Œå¼€å§‹æ’­æ”¾
                self._setup_camera()
                
        finally:
            self.mutex.unlock()
    
    def _setup_video(self):
        """è®¾ç½®è§†é¢‘æ’­æ”¾"""
        try:
            import cv2
            
            self.cap = cv2.VideoCapture(self.video_path)
            if not self.cap.isOpened():
                self.status_updated.emit(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {self.video_path}")
                return False
            
            # è·å–è§†é¢‘ä¿¡æ¯
            self.total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
            self.fps = self.cap.get(cv2.CAP_PROP_FPS)
            if self.fps <= 0:
                self.fps = AppConfig.VIDEO_SETTINGS['min_fps']
            
            self.duration = self.total_frames / self.fps if self.fps > 0 else 0
            
            # è®¾ç½®å®šæ—¶å™¨é—´éš”
            interval = int(1000 / self.fps) if self.fps > 0 else 33
            if hasattr(self, 'play_timer'):
                self.play_timer.setInterval(max(1, interval))
                
                # å¯åŠ¨å®šæ—¶å™¨
                self.play_timer.start()
            
            self.status_updated.emit(f"å¼€å§‹æ’­æ”¾è§†é¢‘: {os.path.basename(self.video_path)}")
            self.status_updated.emit(f"æ€»å¸§æ•°: {self.total_frames}, FPS: {self.fps:.2f}")
            
            return True
            
        except Exception as e:
            self.status_updated.emit(f"è®¾ç½®è§†é¢‘å¤±è´¥: {str(e)}")
            return False
    
    def _setup_camera(self):
        """è®¾ç½®æ‘„åƒå¤´"""
        try:
            import cv2
            
            self.cap = cv2.VideoCapture(self.camera_id)
            if not self.cap.isOpened():
                self.status_updated.emit(f"æ— æ³•æ‰“å¼€æ‘„åƒå¤´: {self.camera_id}")
                return
            
            # è®¾ç½®æ‘„åƒå¤´å‚æ•°
            width, height = AppConfig.CAMERA_SETTINGS['resolution']
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
            
            # å°è¯•è®¾ç½®FPS
            try:
                self.cap.set(cv2.CAP_PROP_FPS, AppConfig.CAMERA_SETTINGS['target_fps'])
            except:
                pass
            
            self.fps = AppConfig.CAMERA_SETTINGS['target_fps']
            
            # è®¾ç½®å®šæ—¶å™¨é—´éš”
            interval = int(1000 / self.fps) if self.fps > 0 else 33
            if hasattr(self, 'play_timer'):
                self.play_timer.setInterval(max(1, interval))
                
                # å¯åŠ¨å®šæ—¶å™¨
                self.play_timer.start()
            
            self.status_updated.emit(f"å¼€å§‹æ‘„åƒå¤´å®æ—¶æ˜¾ç¤º ({width}x{height})")
            
        except Exception as e:
            self.status_updated.emit(f"è®¾ç½®æ‘„åƒå¤´å¤±è´¥: {str(e)}")
    
    def _process_next_frame(self):
        """å¤„ç†ä¸‹ä¸€å¸§ï¼ˆå®šæ—¶å™¨è§¦å‘ï¼‰"""
        if not self._is_running or self._is_paused or not self.cap:
            return
        
        try:
            import cv2
            import numpy as np
            
            # è¯»å–å¸§
            ret, frame = self.cap.read()
            
            if not ret or frame is None:
                # æ’­æ”¾ç»“æŸ
                if self.play_mode == 'video':
                    # è§†é¢‘å¾ªç¯æ’­æ”¾
                    self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                    ret, frame = self.cap.read()
                    if not ret:
                        self.stop()
                        return
                else:
                    # æ‘„åƒå¤´å‡ºé”™
                    self.stop()
                    return
            
            # æ›´æ–°å½“å‰å¸§å·
            if self.play_mode == 'video':
                self.current_frame_num = int(self.cap.get(cv2.CAP_PROP_POS_FRAMES))
            else:
                self.current_frame_num += 1
            
            # ä¿å­˜å½“å‰å¸§
            self.current_frame = frame.copy() if hasattr(frame, 'copy') else frame
            
            # å‘é€åŸå§‹å¸§ç»™æ¨ç†å™¨ï¼ˆä½¿ç”¨objectä¿¡å·é¿å…numpyä¾èµ–é—®é¢˜ï¼‰
            self.raw_frame_ready.emit(self.current_frame)
            
            # å‡†å¤‡æ˜¾ç¤ºå¸§å¹¶å‘é€ç»™UI
            display_qimg = self._frame_to_qimage(self.current_frame)
            self.display_frame_ready.emit(display_qimg)
            
        except Exception as e:
            self.status_updated.emit(f"å¤„ç†å¸§å¤±è´¥: {str(e)}")
    
    def _frame_to_qimage(self, frame) -> QImage:
        """å°†å¸§è½¬æ¢ä¸ºQImage"""
        try:
            import cv2
            import numpy as np
            
            if not isinstance(frame, np.ndarray) or frame.size == 0:
                return QImage()
            
            # ç¡®ä¿æ˜¯3é€šé“BGRå›¾åƒ
            if len(frame.shape) == 2:
                frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)
            elif frame.shape[2] == 4:
                frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)
            elif frame.shape[2] != 3:
                frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
            
            # ç¡®ä¿å†…å­˜è¿ç»­
            if not frame.flags['C_CONTIGUOUS']:
                frame = np.ascontiguousarray(frame)
            
            height, width, channel = frame.shape
            bytes_per_line = 3 * width
            
            return QImage(
                frame.data, width, height, bytes_per_line,
                QImage.Format_BGR888
            ).copy()
            
        except Exception as e:
            print(f"è½¬æ¢å¸§åˆ°QImageå¤±è´¥: {e}")
            return QImage()
    
    def stop(self):
        """åœæ­¢æ’­æ”¾"""
        self.mutex.lock()
        try:
            self._stop_requested = True
            self._is_running = False
            self._is_paused = False
            
            # åœæ­¢å®šæ—¶å™¨
            if hasattr(self, 'play_timer') and self.play_timer.isActive():
                self.play_timer.stop()
            
            # é‡Šæ”¾èµ„æº
            if self.cap:
                try:
                    self.cap.release()
                except:
                    pass
                self.cap = None
            
            # è¯·æ±‚çº¿ç¨‹é€€å‡º
            self.quit()
            if self.isRunning():
                self.wait(1000)
            
            self.playback_finished.emit()
            
        finally:
            self.mutex.unlock()
    
    def pause(self):
        """æš‚åœæ’­æ”¾"""
        self.mutex.lock()
        try:
            if self._is_running and not self._is_paused:
                self._is_paused = True
                if hasattr(self, 'play_timer') and self.play_timer.isActive():
                    self.play_timer.stop()
        finally:
            self.mutex.unlock()
    
    def resume(self):
        """æ¢å¤æ’­æ”¾"""
        self.mutex.lock()
        try:
            if self._is_running and self._is_paused:
                self._is_paused = False
                if hasattr(self, 'play_timer') and not self.play_timer.isActive():
                    self.play_timer.start()
        finally:
            self.mutex.unlock()
    
    def seek_frame(self, target_frame: int):
        """è·³è½¬åˆ°æŒ‡å®šå¸§ï¼ˆä»…è§†é¢‘æ¨¡å¼ï¼‰"""
        if not self.cap or self.play_mode != 'video':
            return
        
        try:
            import cv2
            
            # æš‚åœæ’­æ”¾
            was_playing = hasattr(self, 'play_timer') and self.play_timer.isActive()
            if was_playing:
                self.play_timer.stop()
            
            # è·³è½¬
            self.cap.set(cv2.CAP_PROP_POS_FRAMES, max(0, min(target_frame, self.total_frames - 1)))
            
            # è¯»å–ä¸€å¸§
            ret, frame = self.cap.read()
            if ret and frame is not None:
                self.current_frame = frame.copy()
                self.current_frame_num = target_frame
                
                # å‘é€åŸå§‹å¸§
                self.raw_frame_ready.emit(self.current_frame)
                
                # å‘é€æ˜¾ç¤ºå¸§
                display_qimg = self._frame_to_qimage(self.current_frame)
                self.display_frame_ready.emit(display_qimg)
            
            # æ¢å¤æ’­æ”¾
            if was_playing and not self._is_paused:
                self.play_timer.start()
                
        except Exception as e:
            self.status_updated.emit(f"è·³è½¬å¤±è´¥: {str(e)}")
    
    def get_current_frame(self):
        """è·å–å½“å‰å¸§"""
        self.mutex.lock()
        try:
            if self.current_frame is not None and hasattr(self.current_frame, 'copy'):
                return self.current_frame.copy()
            return None
        finally:
            self.mutex.unlock()
    
    def run(self):
        """çº¿ç¨‹ä¸»å¾ªç¯"""
        self.status_updated.emit("æ’­æ”¾å™¨çº¿ç¨‹å¯åŠ¨")
        
        try:
            # åœ¨run()å†…éƒ¨åˆ›å»ºQTimerï¼ˆç¡®ä¿åœ¨åŒä¸€çº¿ç¨‹ï¼‰
            self.play_timer = QTimer()
            self.play_timer.timeout.connect(self._process_next_frame)
            
            # æ ¹æ®æ’­æ”¾æ¨¡å¼è®¾ç½®
            if self.play_mode == 'video' and self.video_path:
                self._setup_video()
            elif self.play_mode == 'camera' and self.camera_id is not None:
                self._setup_camera()
            else:
                return
            
            # è¿›å…¥äº‹ä»¶å¾ªç¯
            self.exec_()
            
        except Exception as e:
            self.status_updated.emit(f"æ’­æ”¾å™¨é”™è¯¯: {str(e)}")
            traceback.print_exc()
        finally:
            # æ¸…ç†
            if hasattr(self, 'play_timer') and self.play_timer.isActive():
                self.play_timer.stop()
            
            if self.cap:
                try:
                    self.cap.release()
                except:
                    pass
                self.cap = None
            
            self.status_updated.emit("æ’­æ”¾å™¨çº¿ç¨‹ç»“æŸ")


class YOLOMainController(QObject):
    """é‡æ„åçš„ä¸»é€»è¾‘æ§åˆ¶å™¨"""
    
    def __init__(self, ui_window: YOLOMainWindowUI):
        super().__init__()
        self.ui = ui_window
        
        # æ ¸å¿ƒç»„ä»¶
        self.video_player = VideoPlayerThread()  # ç®€åŒ–ç‰ˆæ’­æ”¾å™¨
        self.detector_worker = DetectorWorker()  # ç‹¬ç«‹æ¨ç†å™¨
        self.yolo_processor = None               # YOLOæ¨ç†å¼•æ“
        
        # çŠ¶æ€å˜é‡
        self.model_loaded = False
        self.model_path = None
        self.model_mode = None
        
        # å¤„ç†çŠ¶æ€
        self.is_processing = False      # æ˜¯å¦æ­£åœ¨YOLOå¤„ç†
        self.is_playing = False         # æ˜¯å¦æ­£åœ¨æ’­æ”¾
        self.current_file = None
        self.current_mode = None        # 'image', 'video', 'camera'
        
        # å‚æ•°
        self.default_params = {
            'iou_threshold': AppConfig.YOLO_SETTINGS['default_iou'],
            'confidence_threshold': AppConfig.YOLO_SETTINGS['default_confidence'],
            'delay_ms': 10,
            'line_width': AppConfig.YOLO_SETTINGS['default_line_width']
        }
        
        # è·å–UIç»„ä»¶å¼•ç”¨
        self.left_panel = self.ui.get_left_panel()
        self.right_panel = self.ui.get_right_panel()
        
        # åˆå§‹åŒ–
        self._init_ui_state()
        self._setup_connections()
        
        print("YOLOé€»è¾‘æ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _init_ui_state(self):
        """åˆå§‹åŒ–UIçŠ¶æ€"""
        self.right_panel.set_parameters(**self.default_params)
        self.left_panel.clear_display()
        self.right_panel.update_model_info()
        self.right_panel.set_control_state(False)
    
    def _setup_connections(self):
        """è®¾ç½®æ‰€æœ‰ä¿¡å·è¿æ¥"""
        
        # ===== è§†é¢‘æ’­æ”¾å™¨ä¿¡å·è¿æ¥ =====
        self.video_player.display_frame_ready.connect(self._on_display_frame_ready)
        self.video_player.raw_frame_ready.connect(self.detector_worker.on_frame_received)
        self.video_player.status_updated.connect(self._on_status_updated)
        self.video_player.playback_finished.connect(self._on_playback_finished)
        
        # ===== æ¨ç†å·¥ä½œå™¨ä¿¡å·è¿æ¥ =====
        self.detector_worker.frame_processed.connect(self._on_frame_processed)
        self.detector_worker.detection_stats.connect(self._on_detection_stats)
        self.detector_worker.status_updated.connect(self._on_status_updated)
        self.detector_worker.error_occurred.connect(self._on_detector_error)
        self.detector_worker.processing_complete.connect(self._on_processing_complete)
        
        # ===== UIä¿¡å·è¿æ¥ =====
        # æ–‡ä»¶èœå•
        self.ui.file_menu_init.connect(self._on_file_init)
        self.ui.file_menu_exit.connect(self._on_file_exit)
        
        # å¸®åŠ©èœå•
        self.ui.help_menu_about.connect(self._on_help_about)
        self.ui.help_menu_manual.connect(self._on_help_manual)
        
        # ä¸»è¦åŠŸèƒ½
        self.ui.model_load.connect(self.handle_load_model)
        self.ui.image_open.connect(self.handle_open_image)
        self.ui.video_open.connect(self.handle_open_video)
        self.ui.camera_open.connect(self.handle_open_camera)
        self.ui.detect_settings.connect(self.handle_detect_settings)
        
        # æ§åˆ¶æŒ‰é’®
        self.right_panel.start_inference.connect(self.handle_start_inference)
        self.right_panel.stop_inference.connect(self.handle_stop_inference)
        self.right_panel.save_screenshot.connect(self.handle_save_screenshot)
        
        # æ’­æ”¾æ§åˆ¶
        self.ui.left_panel_play_pause.connect(self.handle_play_pause)
        # åˆ é™¤_on_progress_updatedæ–¹æ³•ï¼Œè¿›åº¦æ¡å·²ç§»é™¤
        
        # å‚æ•°å˜åŒ–
        self.right_panel.iou_changed.connect(self.handle_iou_change)
        self.right_panel.confidence_changed.connect(self.handle_confidence_change)
        self.right_panel.delay_changed.connect(self.handle_delay_change)
        self.right_panel.line_width_changed.connect(self.handle_line_width_change)
    
    # ============================================================================
    # ä¿¡å·å¤„ç†æ–¹æ³•
    # ============================================================================
    
    @Slot(QImage)
    def _on_display_frame_ready(self, q_image: QImage):
        """æ˜¾ç¤ºå¸§å°±ç»ªï¼ˆæ¥è‡ªæ’­æ”¾å™¨ï¼‰"""
        try:
            if not self.is_processing:
                pixmap = QPixmap.fromImage(q_image)
                self.left_panel.set_display_image(pixmap)
        except Exception as e:
            print(f"æ˜¾ç¤ºåŸå§‹å¸§å¤±è´¥: {e}")
    
    @Slot(QImage)
    def _on_frame_processed(self, q_image: QImage):
        """å¤„ç†åçš„å¸§å°±ç»ªï¼ˆæ¥è‡ªæ¨ç†å™¨ï¼‰"""
        try:
            pixmap = QPixmap.fromImage(q_image)
            self.left_panel.set_display_image(pixmap)
        except Exception as e:
            print(f"æ˜¾ç¤ºå¤„ç†å¸§å¤±è´¥: {e}")
    
    @Slot(dict)
    def _on_detection_stats(self, stats: dict):
        """æ£€æµ‹ç»Ÿè®¡ä¿¡æ¯"""
        try:
            self.right_panel.update_statistics(
                detection_count=stats.get('detection_count', 0),
                confidence=stats.get('avg_confidence', 0.0),
                inference_time=stats.get('inference_time', 0),
                fps=stats.get('fps', 0.0)
            )
        except Exception as e:
            print(f"æ›´æ–°ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
    
    @Slot(str)
    def _on_status_updated(self, status: str):
        """çŠ¶æ€æ›´æ–°"""
        print(f"çŠ¶æ€: {status}")
    
    @Slot(str)
    def _on_detector_error(self, error_msg: str):
        """æ¨ç†å™¨é”™è¯¯"""
        print(f"æ¨ç†å™¨é”™è¯¯: {error_msg}")
    
    @Slot()
    def _on_processing_complete(self):
        """å¤„ç†å®Œæˆ"""
        self.is_processing = False
        self.right_panel.set_control_state(False)
        print("æ¨ç†å¤„ç†å®Œæˆ")
    
    @Slot()
    def _on_playback_finished(self):
        """æ’­æ”¾å®Œæˆ"""
        self.is_playing = False
        self.left_panel.set_play_state(False)
        print("æ’­æ”¾å®Œæˆ")
    
    @Slot()
    def handle_play_pause(self):
        """æ’­æ”¾/æš‚åœ"""
        try:
            if self.current_mode in ['video', 'camera']:
                if self.video_player._is_paused:
                    self.video_player.resume()
                    self.left_panel.set_play_state(True)
                else:
                    self.video_player.pause()
                    self.left_panel.set_play_state(False)
        except Exception as e:
            print(f"æ’­æ”¾/æš‚åœå¤±è´¥: {e}")
    
    # ============================================================================
    # æ–‡ä»¶å¤„ç†æ–¹æ³•
    # ============================================================================
    
    def handle_load_model(self):
        """åŠ è½½æ¨¡å‹ï¼ˆä¸åŸé€»è¾‘ç›¸åŒï¼‰"""
        try:
            model_filter = AppConfig.FILE_SETTINGS['file_filters']['model']
            model_path, _ = QFileDialog.getOpenFileName(
                self.ui, "é€‰æ‹©YOLOæ¨¡å‹æ–‡ä»¶", "", model_filter
            )
            
            if model_path:
                self.model_path = None
                self.model_mode = None
                self.yolo_processor = None
                self.model_loaded = False
                
                print(f"å¼€å§‹åˆ†ææ¨¡å‹: {model_path}")
                
                try:
                    from yolo_analyzer import UnifiedYOLO
                    model_info = UnifiedYOLO.analyze_model_info(model_path)
                    
                    if model_info:
                        model_name = os.path.basename(model_path)
                        task_type = model_info.get('task_type', 'detection')
                        input_size = model_info.get('input_size', '640x640')
                        class_count = model_info.get('class_count', 'æœªçŸ¥')
                        
                        task_display_map = AppConfig.TASK_CONFIG['task_display_map']
                        display_name = task_display_map.get(task_type, task_type)
                        self.model_mode = task_type
                        
                        self.right_panel.update_model_info(
                            model_path=model_path,
                            task_type=display_name,
                            input_size=input_size,
                            class_count=class_count
                        )
                        
                        self.model_path = model_path
                        
                        QMessageBox.information(
                            self.ui, "æ¨¡å‹åˆ†ææˆåŠŸ",
                            f"âœ… å·²è‡ªåŠ¨è¯†åˆ«æ¨¡å‹ç±»å‹\n\n"
                            f"ğŸ“¦ æ¨¡å‹: {model_name}\n"
                            f"ğŸ¯ ä»»åŠ¡ç±»å‹: {display_name}\n"
                            f"ğŸ“ è¾“å…¥å°ºå¯¸: {input_size}\n"
                            f"ğŸ”¢ ç±»åˆ«æ•°é‡: {class_count}\n\n"
                            f"æ¨¡å‹å°†åœ¨ç‚¹å‡»'å¼€å§‹'æ—¶æ­£å¼åŠ è½½ã€‚"
                        )
                        
                    else:
                        raise Exception("æ— æ³•è¯†åˆ«æ¨¡å‹ç±»å‹")
                    
                except Exception as e:
                    print(f"æ¨¡å‹åˆ†æå¤±è´¥: {e}")
                    self._show_model_type_dialog(model_path)
                    
        except Exception as e:
            self._show_error("é€‰æ‹©æ¨¡å‹å¤±è´¥", str(e))
    
    def handle_open_image(self):
        """æ‰“å¼€å›¾ç‰‡"""
        try:
            self._stop_all()
            
            image_filter = AppConfig.FILE_SETTINGS['file_filters']['image']
            image_path, _ = QFileDialog.getOpenFileName(
                self.ui, "é€‰æ‹©å›¾ç‰‡æ–‡ä»¶", "", image_filter
            )
            
            if image_path:
                self.current_file = image_path
                self.current_mode = 'image'
                
                self.left_panel.update_info(os.path.basename(image_path), 'image')
                
                pixmap = QPixmap(image_path)
                if not pixmap.isNull():
                    self.left_panel.set_display_image(pixmap)
                    print(f"å·²åŠ è½½å›¾ç‰‡: {os.path.basename(image_path)}")
                else:
                    QMessageBox.warning(self.ui, "è­¦å‘Š", "æ— æ³•åŠ è½½å›¾ç‰‡æ–‡ä»¶")
                
        except Exception as e:
            self._show_error("æ‰“å¼€å›¾ç‰‡å¤±è´¥", str(e))
    
    def handle_open_video(self):
        """æ‰“å¼€è§†é¢‘"""
        try:
            self._stop_all()
            
            video_filter = AppConfig.FILE_SETTINGS['file_filters']['video']
            video_path, _ = QFileDialog.getOpenFileName(
                self.ui, "é€‰æ‹©è§†é¢‘æ–‡ä»¶", "", video_filter
            )
            
            if video_path:
                self.current_file = video_path
                self.current_mode = 'video'
                self.is_playing = True
                
                self.left_panel.update_info(os.path.basename(video_path), 'video')
                self.video_player.play_video(video_path)
                self.left_panel.set_play_state(True)
                
                print(f"å¼€å§‹æ’­æ”¾è§†é¢‘: {os.path.basename(video_path)}")
                
        except Exception as e:
            self._show_error("æ‰“å¼€è§†é¢‘å¤±è´¥", str(e))
    
    def handle_open_camera(self):
        """æ‰“å¼€æ‘„åƒå¤´"""
        try:
            self._stop_all()
            
            camera_id = AppConfig.CAMERA_SETTINGS['default_camera_id']
            
            self.current_file = f"æ‘„åƒå¤´ {camera_id}"
            self.current_mode = 'camera'
            self.is_playing = True
            
            self.left_panel.update_info(f"æ‘„åƒå¤´ {camera_id}", 'camera')
            self.video_player.play_camera(camera_id)
            self.left_panel.set_play_state(True)
            
            print(f"å¼€å§‹æ‘„åƒå¤´å®æ—¶æ˜¾ç¤º")
                
        except Exception as e:
            self._show_error("æ‰“å¼€æ‘„åƒå¤´å¤±è´¥", str(e))
    
    # ============================================================================
    # æ¨ç†æ§åˆ¶æ–¹æ³•
    # ============================================================================
    
    def handle_start_inference(self):
        """å¼€å§‹æ¨ç†"""
        try:
            # æ£€æŸ¥å¿…è¦æ¡ä»¶
            if not self.current_file:
                QMessageBox.warning(self.ui, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©åª’ä½“æ–‡ä»¶ï¼")
                return
            
            if not self.model_path or not self.model_mode:
                QMessageBox.warning(self.ui, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©æ¨¡å‹ï¼")
                return
            
            # åŠ è½½æ¨¡å‹
            if not self._load_yolo_processor():
                return
            
            # è®¾ç½®æ¨ç†å™¨å‚æ•°
            params = self.right_panel.get_parameters()
            delay_ms = params.get('delay_ms', 10)
            
            # æ ¹æ®å»¶è¿Ÿè®¡ç®—å¤„ç†é—´éš”ï¼ˆå»¶è¿Ÿè¶Šå¤§ï¼Œå¤„ç†é—´éš”è¶Šå¤§ï¼‰
            process_interval = max(1, delay_ms // 10)
            self.detector_worker.set_process_interval(process_interval)
            
            # è®¾ç½®YOLOå¤„ç†å™¨åˆ°æ¨ç†å™¨
            self.detector_worker.set_yolo_processor(self.yolo_processor)
            
            # å¼€å§‹æ¨ç†
            success = self.detector_worker.start_processing()
            if success:
                self.is_processing = True
                self.right_panel.set_control_state(True)
                print(f"å¼€å§‹{self.current_mode}å¤„ç†ï¼Œå¤„ç†é—´éš”: æ¯{process_interval}å¸§å¤„ç†ä¸€æ¬¡")
            else:
                QMessageBox.warning(self.ui, "è­¦å‘Š", "æ— æ³•å¯åŠ¨æ¨ç†å¤„ç†")
                
        except Exception as e:
            self._show_error("å¼€å§‹å¤„ç†å¤±è´¥", str(e))
    
    def handle_stop_inference(self):
        """åœæ­¢æ¨ç†"""
        self.detector_worker.stop_processing()
        self.is_processing = False
        self.right_panel.set_control_state(False)
        print("æ¨ç†å¤„ç†å·²åœæ­¢")
    
    def _load_yolo_processor(self) -> bool:
        """åŠ è½½YOLOå¤„ç†å™¨"""
        try:
            if not self.model_path or not self.model_mode:
                QMessageBox.warning(self.ui, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©æ¨¡å‹ï¼")
                return False
            
            if self.yolo_processor is not None:
                print("YOLOå¤„ç†å™¨å·²åŠ è½½ï¼Œè·³è¿‡é‡å¤åŠ è½½")
                return True
            
            # è·å–å‚æ•°
            params = self.right_panel.get_parameters()
            
            print(f"æ­£åœ¨åŠ è½½YOLOæ¨¡å‹: {os.path.basename(self.model_path)}")
            
            # åˆ›å»ºYOLOå¤„ç†å™¨
            self.yolo_processor = UnifiedYOLO(
                model_path=self.model_path,
                mode=self.model_mode,
                conf_threshold=params['confidence_threshold'],
                iou_threshold=params['iou_threshold']
            )
            
            self.model_loaded = True
            
            # è·å–æ¨¡å‹ä¿¡æ¯
            model_info = self.yolo_processor.get_model_info()
            
            # æ›´æ–°UI
            task_display_map = AppConfig.TASK_CONFIG['task_display_map']
            display_name = task_display_map.get(self.model_mode, self.model_mode)
            input_size_str = f"{model_info.get('input_size', 640)}"
            class_count = model_info.get('class_count', model_info.get('num_classes', 'æœªçŸ¥'))
            
            self.right_panel.update_model_info(
                model_path=self.model_path,
                task_type=display_name,
                input_size=input_size_str,
                class_count=str(class_count)
            )
            
            print(f"âœ… YOLOå¤„ç†å™¨åŠ è½½æˆåŠŸ")
            return True
                
        except Exception as e:
            self._show_error("åŠ è½½YOLOå¤„ç†å™¨å¤±è´¥", str(e))
            return False
    
    # ============================================================================
    # å…¶ä»–æ–¹æ³•
    # ============================================================================
    
    def _stop_all(self):
        """åœæ­¢æ‰€æœ‰å¤„ç†"""
        self.detector_worker.stop_processing()
        self.video_player.stop()
        self.is_processing = False
        self.is_playing = False
        self.right_panel.set_control_state(False)
    
    def _format_time(self, seconds):
        """æ ¼å¼åŒ–æ—¶é—´"""
        try:
            minutes = int(seconds // 60)
            secs = int(seconds % 60)
            return f"{minutes:02d}:{secs:02d}"
        except:
            return "--:--"
    
    def _show_error(self, title: str, message: str):
        """æ˜¾ç¤ºé”™è¯¯"""
        QMessageBox.critical(
            self.ui, title,
            f"{message}\n\nè¯¦ç»†ä¿¡æ¯è¯·æŸ¥çœ‹æ§åˆ¶å°è¾“å‡ºã€‚"
        )
        print(f"é”™è¯¯ [{title}]: {message}")
        traceback.print_exc()
    
    # å‚æ•°æ›´æ–°æ–¹æ³•ï¼ˆä¸åŸé€»è¾‘ç›¸åŒï¼‰"""
    def handle_iou_change(self, value):
        self.default_params['iou_threshold'] = value
        if self.yolo_processor:
            self.yolo_processor.update_params(iou_threshold=value)
            self.detector_worker.update_parameters(iou_threshold=value)
    
    def handle_confidence_change(self, value):
        """å¤„ç†ç½®ä¿¡åº¦é˜ˆå€¼å˜åŒ–
        
        Args:
            value: æ–°çš„ç½®ä¿¡åº¦é˜ˆå€¼
        """
        self.default_params['confidence_threshold'] = value
        if self.yolo_processor:
            success = self.yolo_processor.update_params(conf_threshold=value)  # æ”¹ä¸ºconf_threshold
            self.detector_worker.update_parameters(confidence_threshold=value)
            
            if success:
                print(f"ç½®ä¿¡åº¦é˜ˆå€¼å·²æ›´æ–°: {value}")
            else:
                print(f"é”™è¯¯ [æ›´æ–°ç½®ä¿¡åº¦é˜ˆå€¼å¤±è´¥]: æ— æ•ˆçš„é˜ˆå€¼: {value}")
    
    def handle_delay_change(self, value):
        self.default_params['delay_ms'] = value
    
    def handle_line_width_change(self, value):
        self.default_params['line_width'] = value
        if self.yolo_processor:
            self.yolo_processor.update_params(line_width=value)
            self.detector_worker.update_parameters(line_width=value)
    
    def handle_save_screenshot(self):
        """ä¿å­˜æˆªå›¾"""
        try:
            pixmap = self.left_panel.display_label.pixmap()
            if pixmap and not pixmap.isNull():
                # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ–‡ä»¶è¿‡æ»¤å™¨
                file_filter = AppConfig.FILE_SETTINGS['file_filters']['screenshot']
                
                if self.current_file:
                    base_name = os.path.splitext(os.path.basename(self.current_file))[0]
                else:
                    base_name = "screenshot"
                
                default_name = f"{base_name}.png"
                
                save_path, _ = QFileDialog.getSaveFileName(
                    self.ui, "ä¿å­˜æˆªå›¾",
                    default_name,
                    file_filter
                )
                
                if save_path:
                    if not save_path.lower().endswith(('.png', '.jpg', '.jpeg')):
                        save_path += '.png'
                    
                    success = pixmap.save(save_path)
                    if success:
                        QMessageBox.information(self.ui, "ä¿å­˜æˆåŠŸ", f"æˆªå›¾å·²ä¿å­˜åˆ°:\n{save_path}")
                        print(f"æˆªå›¾ä¿å­˜åˆ°: {save_path}")
                    else:
                        QMessageBox.warning(self.ui, "ä¿å­˜å¤±è´¥", "æ— æ³•ä¿å­˜æˆªå›¾")
            else:
                QMessageBox.warning(self.ui, "è­¦å‘Š", "æ²¡æœ‰å¯ä¿å­˜çš„å›¾åƒ")
                
        except Exception as e:
            self._show_error("ä¿å­˜æˆªå›¾å¤±è´¥", str(e))

    def handle_detect_settings(self):
        """æ£€æµ‹è®¾ç½® - é€šè¿‡UIæ–¹æ³•æ˜¾ç¤ºæ£€æµ‹è®¾ç½®å¯¹è¯æ¡†"""
        self.ui.show_detect_settings_dialog()
    
    def _show_model_type_dialog(self, model_path):
        """æ¨¡å‹ç±»å‹é€‰æ‹©å¯¹è¯æ¡†"""
        # ä¿æŒåŸæœ‰é€»è¾‘
        pass
    
    def _select_model_type(self, model_type, model_path, dialog):
        """é€‰æ‹©æ¨¡å‹ç±»å‹"""
        # ä¿æŒåŸæœ‰é€»è¾‘
        pass
    
    # æ–‡ä»¶èœå•å¤„ç†æ–¹æ³•
    def _on_file_init(self):
        """åˆå§‹åŒ–"""
        reply = QMessageBox.question(
            self.ui, "ç¡®è®¤åˆå§‹åŒ–", "æ˜¯å¦è¦åˆå§‹åŒ–æ‰€æœ‰è®¾ç½®ï¼Ÿ",
            QMessageBox.Yes | QMessageBox.No, QMessageBox.No
        )
        if reply == QMessageBox.Yes:
            self._stop_all()
            self._init_ui_state()
            QMessageBox.information(self.ui, "åˆå§‹åŒ–å®Œæˆ", "æ‰€æœ‰è®¾ç½®å·²é‡ç½®")
    
    def _on_file_exit(self):
        """é€€å‡º - é€šè¿‡UIæ–¹æ³•æ˜¾ç¤ºç¡®è®¤å¯¹è¯æ¡†"""
        if self.ui.show_confirm_exit_dialog():
            self._stop_all()
            self.ui.close()
    
    # å¸®åŠ©èœå•å¤„ç†æ–¹æ³•
    def _on_help_about(self):
        """å…³äº - é€šè¿‡UIæ–¹æ³•æ˜¾ç¤ºå…³äºå¯¹è¯æ¡†"""
        self.ui.show_about_dialog()
    
    def _on_help_manual(self):
        """ä½¿ç”¨è¯´æ˜ - é€šè¿‡UIæ–¹æ³•æ˜¾ç¤ºä½¿ç”¨è¯´æ˜å¯¹è¯æ¡†"""
        self.ui.show_help_manual_dialog()

